from geopy.geocoders import Nominatim
import pandas as pd
import numpy as np
df=pd.read_csv("Luxury_Housing_Bangalore.csv")
df.head
df.tail
df.columns = df.columns.str.lower()
df.size
df.shape
df.describe()
df.info()
df.dtypes
df.columns
df.index
df.isnull().sum()
df.duplicated().sum()
df.drop_duplicates(inplace=True)
df['ticket_price_cr']=df['ticket_price_cr'].replace(r'â‚¹|Cr', '', regex=True).astype('float64').round(2)

df[['amenity_score','connectivity_score','locality_infra_score']]=(
    df[['amenity_score','connectivity_score','locality_infra_score']].round(2))
df['micro_market']=df['micro_market'].str.strip().str.lower()
df['micro_market']=df['micro_market'].replace({'jayanagar': 'JAYANAGAR','bannerghatta road': 'BANNERGHATTA ROAD','mg road': 'MG ROAD',
                                               'jp nagar': 'JP NAGAR','sarjapur road': 'SARJAPUR ROAD','indiranagar': 'INDIRANAGAR',
                                                'kanakapura road': 'KANAKAPURA ROAD','yelahanka': 'YELAHANKA','hennur road': 'HENNUR ROAD',
                                                'koramangala': 'KORAMANGALA','domlur': 'DOMLUR','hebbal': 'HEBBAL',
                                                'electronic city': 'ELECTRONIC CITY','bellary road': 'BELLARY ROAD','rajajinagar': 'RAJAJINAGAR',
                                                'whitefield': 'WHITEFIELD'})

df['micro_market'].value_counts()

df['configuration']=df['configuration'].str.strip().replace({'5Bhk+':'5BHK+','5bhk+':'5BHK+','3Bhk':'3BHK','4Bhk':'4BHK','4bhk':'4BHK','3bhk':'3BHK'})
df['configuration'].value_counts()
df['purchase_quarter']=pd.to_datetime(df['purchase_quarter'])
df['quarter']=df['purchase_quarter'].dt.quarter.astype('int64')
df['year']=df['purchase_quarter'].dt.year.astype('int64')
df['price_per_sqft']=(df['ticket_price_cr'] * 1e7 / df['unit_size_sqft']).round(2)

#Transform ->Apply group-based calculation, keep original shape	
# df['GroupMean'] = df.groupby('Category')['Sales'].transform('mean')	
# Adds new column with group mean	
# Useful when you need results same shape as original

row_median=df.groupby('ticket_price_cr')['price_per_sqft'].transform('median')
column_median=df['price_per_sqft'].median(skipna=True)

# Fill NaNs: first with group median, then with overall median
df['price_per_sqft'] = df['price_per_sqft'].fillna(row_median).fillna(column_median)
df['unit_size_sqft'].info()
df['unit_size_sqft'].value_counts()
#Ignoring the -1 Values
df = df.loc[df['unit_size_sqft'] != -1.0]
df['unit_size_sqft'].value_counts()
#It works column-vise
df['unit_size_sqft'] = df.groupby('configuration')['unit_size_sqft'].transform(lambda x: x.fillna(x.median()))
df['ticket_price_cr'] = df.groupby(['micro_market','configuration'])['ticket_price_cr'].transform(lambda x: x.fillna(x.median()))
df['amenity_score'] = df['amenity_score'].fillna(df['amenity_score'].median())
df['buyer_comments'] = df['buyer_comments'].fillna("No Comments")
#It works row-vise
df['booking_status'] = df['possession_status'].apply(lambda x: 'Booked' if x == 'Ready to move' else 'Not Booked')
geolocator=Nominatim(user_agent="Map")

lat_long = {'micro_market': [], 'lat': [], 'lon': []}
for i in df['micro_market'].unique():
    location=geolocator.geocode(f"{i}, Bangalore, India")
    lat=location.latitude
    lon=location.longitude
    lat_long['micro_market'].append(i)
    lat_long['lat'].append(lat)
    lat_long['lon'].append(lon)
    #print(i,lat,lon)

micro_market_df=pd.DataFrame(lat_long)
df=pd.merge(df,micro_market_df,on='micro_market')
df.drop(columns='project_name', inplace=True)
df
import psycopg2

#Establishing the connection between Py and SQL
conn=psycopg2.connect(
    database="postgres",
    user="postgres",
    password="281299",
    host="localhost",
    port="5432")

#cursor is used to execute commands in SQL
cur = conn.cursor()
conn.autocommit=True
#Creating new DB 
new_db_name="housing_sales"
cur.execute(f"CREATE DATABASE {new_db_name}")
cur = conn.cursor()
from sqlalchemy import create_engine

engine = create_engine("postgresql+psycopg2://postgres:281299@localhost:5432/housing_sales")

df.to_sql("housing_sales_data", engine, if_exists="replace", index=False)
